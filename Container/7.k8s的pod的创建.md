### Pod创建流程

客户端提交创建请求，通过Api Server的Restful Api，也可以通过kubectl命令工具，支持json和yaml两种格式

**Master节点:**

1. Api Server处理用户请求，存储Pod数据到etcd

2. Scheduler通过Api Server查看未绑定的Pod，尝试为Pod分配主机，这里的分配流程下面讲述，然后选择主机后，进行
Binding操作，结果存储到etcd中

**Node节点:**

1. 运行在node节点上的kubelet会定期与etcd同步bound pod信息，即上面第二步的信息
   
2. 一旦发现在工作节点上运行的bound pod对象没有更新，调用Docker api创建并启动Pod内的容器

3. 然后调用Api Server更新etcd信息


### Pod调度流程

#### 1. 影响调度的属性

- Pod的资源限制


      resources:
        requests:
            memory: "64Mi"
            cpu: "250m"

- 节点选择器标签


    spec:
        nodeSelector:
            env: dev

可以通过标签，将节点进行分组，比如分为开发环境、测试环境、生产环境等

    # 通过此命令给节点进行打标签
    kubectl label node k8s-worker1 env=dev

- 节点的亲和性


    spec:
        nodeAffinity:


节点亲和性和NodeSelector基本一样，根据节点上标签约束来决定Pod调度到哪些节点上，
亲和性分为软亲和性和硬亲和性，其中硬亲和性是必须满足；而软亲和性则是通过权重打分，软
亲和性是尝试满足，不一定满足。亲和性操作中支持操作符，如In, NotIn, Exists, Gt, Lt, DoesNotExists


#### 2. 污点和污点容忍

**Taint污点**

节点不做普通分配调度，是节点[node]属性

**场景:** 

- 专用节点
- 配置特定硬件节点
- 基于Taint驱逐

**污点相关命令:**

    # 查看节点污点情况
    kubectl describe node k8smaster | grep Traint

    # 删除污点
    kubectl taint node [node] key=value:污点值Enum-

    # 为节点添加污点
    kubectl taint node [node] key=value:污点值Enum

**污点值Enum:**

- NoSchedule: 一定不会被调度
- PreferNoSchedule: 尽量不会被调度
- NoExecute: 不会调度，并且还会驱逐节点已有Pod
    
**污点容忍**

污点容忍即节点[node]被打上污点，但是依旧可能会被调用到

    spec:
        tolerations:
        - key: "key"
          operator: "Equal"
          value: "value"
          effect: "NoSchedule"

